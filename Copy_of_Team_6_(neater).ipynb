{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Copy of Team_6 (neater).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MIrfaanA/classification-predict-streamlit-template/blob/master/Copy_of_Team_6_(neater).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f929e9e"
      },
      "source": [
        "## 2021/22 Climate Change Belief Analysis Predict Solution"
      ],
      "id": "0f929e9e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64599664"
      },
      "source": [
        "<img src=\"https://1qa2mv1tvhvk1t1uyv1mvwyx1dmd-wpengine.netdna-ssl.com/files/2014/01/Twitter-350.jpg\"\n",
        "     alt=\"Learn good habits to avoid modeling debt\"\n",
        "     style=\"float: center; padding-bottom=0.5em\"\n",
        "     width=700px\n",
        "     height=500px/>"
      ],
      "id": "64599664"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79c0835a"
      },
      "source": [
        "### Team 6 \n",
        "\n",
        "- Floyd Skakane\n",
        "- Lehlogonolo Jesica Teffo\n",
        "- Muhammed Irfaan Ahmed\n",
        "- Mulalo Malange\n",
        "- Vuyisile Ngobeni\n"
      ],
      "id": "79c0835a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed63299c"
      },
      "source": [
        "### Supervisor\n",
        "James Combrink"
      ],
      "id": "ed63299c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74ac4248"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "Many companies are built around lessening one’s environmental impact or carbon footprint.They offer  products and services that are environmentally friendly and sustainable, in line with their values  and ideals.They would like to determine how people perceive climate change and whether or not they believe  it is a real threat.This would add to their market research efforts in gauging how their product/service may be received."
      ],
      "id": "74ac4248"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98fb3686"
      },
      "source": [
        "### Problem statement"
      ],
      "id": "98fb3686"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ab47ec4"
      },
      "source": [
        "We are tasked to create a Machine Learning model that is able to classify whether or not a person believes in climate change,\n",
        "based on their novel tweet data.Providing an accurate and robust solution to this task gives companies access to a broad base\n",
        "of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing\n",
        "future marketing strategies."
      ],
      "id": "2ab47ec4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bfe9121"
      },
      "source": [
        "### Aim \n",
        "To predict an individual’s belief in climate change based on historical tweet data."
      ],
      "id": "8bfe9121"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e90bfeb9"
      },
      "source": [
        "### Data description\n",
        "\n",
        "- The collection of this data was funded by a Canada Foundation for Innovation JELF Grant to Chris Bauch, University of   Waterloo.\n",
        "- The dataset aggregates tweets pertaining to climate change collected between Apr 27, 2015 and Feb 21, 2018. \n",
        "- In total, 43943 tweets were collected. \n",
        "- Each tweet is labelled as one of the following classes:\n",
        "\n",
        "Class description:\n",
        "\n",
        "- 2 News: the tweet links to factual news about climate change\n",
        "- 1 Pro: the tweet supports the belief of man-made climate change\n",
        "- 0 Neutral: the tweet neither supports nor refutes the belief of man-made climate change\n",
        "- -1 Anti: the tweet does not believe in man-made climate change\n",
        "- Columns:\n",
        "- sentiment: Sentiment of tweet i.e 0, 1, etc\n",
        "- message: Tweet body\n",
        "- tweetid: Twitter unique id\n"
      ],
      "id": "e90bfeb9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2e43442"
      },
      "source": [
        "<a id=\"cont\"></a>\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "<a href=#one>1. Importing Packages</a>\n",
        "\n",
        "<a href=#two>2. Loading Data</a>\n",
        "\n",
        "<a href=#three>3. Data Preprocessing</a>\n",
        "\n",
        "<a href=#four>4. Exploratory Data Analysis (EDA)</a>\n",
        "\n",
        "<a href=#five>5. Data Engineering</a>\n",
        "\n",
        "<a href=#six>6. Modeling</a>\n",
        "\n",
        "<a href=#seven>7. Model Performance</a>\n",
        "\n",
        "<a href=#eight>8. Model Explanation</a>\n",
        "\n",
        "<a href=#nine>9. Conculsion</a>"
      ],
      "id": "b2e43442"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3da44bce"
      },
      "source": [
        "### 1. Importing Packages"
      ],
      "id": "3da44bce"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aff08899",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7f81202-6622-4e21-d059-4e92881e20bb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.porter import *\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# ML Libraries\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "import os\n",
        "\n",
        "# Global Parameters\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Setting global constants to ensure notebook results are reproducible\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 20)\n",
        "sns.set(rc={'figure.figsize':(12,8)})"
      ],
      "id": "aff08899",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e11d4dbb"
      },
      "source": [
        "### 2. Loading Data"
      ],
      "id": "e11d4dbb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9ddd94f"
      },
      "source": [
        "# Loading train and test data from csv files\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_test = pd.read_csv(\"test_with_no_labels.csv\")"
      ],
      "id": "c9ddd94f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "052f5c9d"
      },
      "source": [
        "### 3. Data Preprocessing"
      ],
      "id": "052f5c9d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0862c46"
      },
      "source": [
        "- Data preprocessing refers to the technique of cleaning and organizing raw data to make it suitable for a building and  training Machine Learning model.\n",
        "- In this section unecessary data will be droped,null values will be filled with mode, the train and test datasets will be merged so that all the data preprocessing is done simultaneously on both datasets."
      ],
      "id": "c0862c46"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d422681"
      },
      "source": [
        "#### 3.1 Raw Data "
      ],
      "id": "8d422681"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99f782ac"
      },
      "source": [
        "Lets have a look at the raw data to see what the data set contains, before preprocessing"
      ],
      "id": "99f782ac"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c49d6aed",
        "outputId": "fce582ed-3dab-456a-c959-3a2378fc4d7f"
      },
      "source": [
        "#Viewing the train dataset\n",
        "display(df_train.head())\n",
        "print(df_train.shape)\n",
        "print('The train data set consists of 15819 rows and 3 columns')"
      ],
      "id": "c49d6aed",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
              "      <td>625221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
              "      <td>126103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
              "      <td>698562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
              "      <td>573736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
              "      <td>466954</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                            message  tweetid\n",
              "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
              "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
              "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
              "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
              "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(15819, 3)\n",
            "The train data set consists of 15819 rows and 3 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f8b1ea2",
        "outputId": "efc0aecc-f0ac-4f65-f792-5e00980cb474"
      },
      "source": [
        "#Viewing the test dataset\n",
        "display(df_test.head())\n",
        "print(df_test.shape)\n",
        "print('The test data set consists of 10546 rows and 2 columns')"
      ],
      "id": "2f8b1ea2",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Europe will now be looking to China to make su...</td>\n",
              "      <td>169760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Combine this with the polling of staffers re c...</td>\n",
              "      <td>35326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The scary, unimpeachable evidence that climate...</td>\n",
              "      <td>224985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
              "      <td>476263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
              "      <td>872928</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             message  tweetid\n",
              "0  Europe will now be looking to China to make su...   169760\n",
              "1  Combine this with the polling of staffers re c...    35326\n",
              "2  The scary, unimpeachable evidence that climate...   224985\n",
              "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
              "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10546, 2)\n",
            "The test data set consists of 10546 rows and 2 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c324e154"
      },
      "source": [
        "The dataset consist of -----  rows and ---- variables of which -----  is the target variable."
      ],
      "id": "c324e154"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c245e79"
      },
      "source": [
        "print(df_train.shape)\n",
        "print('The train data set consists of 15819 rows and 3 columns')"
      ],
      "id": "3c245e79",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88f7ac4a"
      },
      "source": [
        "# Make a copy of the train data set for cleaning\n",
        "df_clean = df_train.copy()"
      ],
      "id": "88f7ac4a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a76b132d",
        "outputId": "fc7a1aa0-fad0-46fa-85f7-ac27a98d1cc3"
      },
      "source": [
        "#Empty rows in data setup\n",
        "df_clean.isnull().sum()"
      ],
      "id": "a76b132d",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment    0\n",
              "message      0\n",
              "tweetid      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3708d66"
      },
      "source": [
        "### 4. Exploratory Data Analysis"
      ],
      "id": "d3708d66"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce4ab4be"
      },
      "source": [
        "# Make a copy of the df so that if we make mistakes we can always refer to the original df\n",
        "df_clean = df_train.copy()"
      ],
      "id": "ce4ab4be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d61a560"
      },
      "source": [
        "### 5. Data Engineering"
      ],
      "id": "0d61a560"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67dc415f"
      },
      "source": [
        ""
      ],
      "id": "67dc415f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fa34307"
      },
      "source": [
        "### 6. Modeling"
      ],
      "id": "0fa34307"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e333e6a2"
      },
      "source": [
        ""
      ],
      "id": "e333e6a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2de60548"
      },
      "source": [
        "### 7. Model Performance"
      ],
      "id": "2de60548"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e581d5c1"
      },
      "source": [
        ""
      ],
      "id": "e581d5c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c45945cc"
      },
      "source": [
        "### 8. Model Explanation"
      ],
      "id": "c45945cc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34c7e8d4"
      },
      "source": [
        ""
      ],
      "id": "34c7e8d4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a144c2dd"
      },
      "source": [
        "### 9. Conclusion"
      ],
      "id": "a144c2dd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9631b00"
      },
      "source": [
        ""
      ],
      "id": "a9631b00",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa767c63"
      },
      "source": [
        "### Making a submission"
      ],
      "id": "fa767c63"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "625ad4e8"
      },
      "source": [
        ""
      ],
      "id": "625ad4e8",
      "execution_count": null,
      "outputs": []
    }
  ]
}